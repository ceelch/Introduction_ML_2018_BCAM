{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression: Polynomial \n",
    "\n",
    "Introduction to Machine Learning, BCAM & UPV/EHU course, by Carlos Cernuda, Ekhine Irurozki and Aritz Perez.\n",
    "\n",
    "\n",
    "## References \n",
    "\n",
    "* James, G., Witten, D., Hastie, T., & Tibshirani, R. (2013). \n",
    "An introduction to statistical learning (Vol. 112). New York: springer.\n",
    "* Data sets: http://www-bcf.usc.edu/~gareth/ISL/data.html\n",
    "* SCIKIT-LEARN library example http://scikit-learn.org\n",
    "* References Jupyter notebooks:\n",
    "    - R. Jordan Crouser at Smith College for SDS293: Machine Learning (Spring 2016)\n",
    "    http://www.science.smith.edu/~jcrouser/SDS293/labs/lab10-py.html\n",
    "    - General Assembly's Data Science course in Washington, DC\n",
    "    https://github.com/justmarkham/DAT4\n",
    "    - An Introduction to Statistical Learning (James, Witten, Hastie, Tibshirani, 2013) adapted to Python code\n",
    "    https://github.com/JWarmenhoven/ISLR-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "import numpy as np #scientific computing (n-dim arrays, etc)\n",
    "import pandas as pd #data analysis library\n",
    "##########################################################\n",
    "# Plots:\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.pylab as pylab\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import seaborn as sns #visualization library based on matplotlib\n",
    "%matplotlib inline\n",
    "plt.style.use(['seaborn-white'])   \n",
    "params = {'legend.fontsize': 'xx-large',\n",
    "              'figure.figsize': (15, 5),\n",
    "              'axes.labelsize': 'xx-large',\n",
    "              'axes.titlesize':'xx-large',\n",
    "              'xtick.labelsize':'xx-large',\n",
    "              'ytick.labelsize':'xx-large'}    \n",
    "pylab.rcParams.update(params)  #fix the parameters for the plots\n",
    "\n",
    "pd.set_option('display.notebook_repr_html', False)\n",
    "##########################################################\n",
    "# SKLEARN: scikit-learn machine learning tools\n",
    "from sklearn.preprocessing import scale ###Standardize a dataset \n",
    "import sklearn.linear_model as skl_lm ###linear model regression\n",
    "##########################################################\n",
    "# STATSMODELS: provides classes and functions for the estimation of many different statistical models, \n",
    "# as well as for conducting statistical tests, and statistical data exploration.\n",
    "import statsmodels.api as sm ##\n",
    "import statsmodels.formula.api as smf ##\n",
    "##########################################################\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Regression: additive without linear assumptions\n",
    "\n",
    "## Data set: Auto\n",
    "\n",
    "Auto data set: \n",
    "Milles per galleon (mpg) of a car in relation with cylinders, weight, horsepower, etc in 392 different models. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto = pd.read_csv('dataset/Auto.csv', na_values='?').dropna()\n",
    "auto.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.head(3) #show 3 first rows\n",
    "# mpg: milles per galleon (response variable)\n",
    "# cylinders, displacement, horsepower, weight, acceleration (predictors variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "Predict mpg by considering as predictor variable the horsepower. \n",
    "\n",
    "The linear model will be: \n",
    "\n",
    "$$\n",
    "mpg \\sim \\beta_0 +\\beta_1 horsepower\n",
    "$$\n",
    "\n",
    "We can try also a non-linear model (polynomial model of degree two):\n",
    "\n",
    "$$\n",
    "mpf \\sim \\beta_0 +\\beta_1 horsepower +\\beta_2 horsepower^2\n",
    "$$\n",
    "\n",
    "We are going to calculate the estimates coefficients as before and to plot the resulting regression line considering the predictor variable horsepower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lineal regression\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "sns.regplot(auto.horsepower, auto.mpg, order=1, ci=None, scatter_kws={'color':'b'}, color='k')\n",
    "plt.title('Linear regression of mpg using horsepower value')\n",
    "plt.xlim(40,240)\n",
    "plt.ylim(5,55);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial regression of degree (order) 2\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "sns.regplot(auto.horsepower, auto.mpg, order=2, ci=None, scatter_kws={'color':'b'}, color='k')\n",
    "plt.title('Polynomial regression (quadratic) of mpg using horsepower value')\n",
    "plt.xlim(40,240)\n",
    "plt.ylim(5,55);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial regression of degree 5\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "sns.regplot(auto.horsepower, auto.mpg, order=5, ci=None, scatter_kws={'color':'b'}, color='k')\n",
    "plt.title('Polynomial regression (degree 5) of mpg using horsepower value')\n",
    "plt.xlim(40,240)\n",
    "plt.ylim(5,55);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying non-linearity using residual plots\n",
    "\n",
    "Residual plots are a useful graphical tool to identifying non-linear relationships between the predictors and the response. Given a linear regression model, \n",
    "\n",
    "* The linear model:\n",
    "\n",
    "$$\n",
    "\\hat{Y} = \\hat{\\beta}_0 +\\hat{\\beta}_1 horsepower\n",
    "$$\n",
    "\n",
    "* The polynomial model of degree two (quadratic):\n",
    "\n",
    "$$\n",
    "\\hat{Y} = \\hat{\\beta}_0 +\\hat{\\beta}_1 horsepower +\\hat{\\beta}_2 horsepower^2\n",
    "$$\n",
    "\n",
    "* The residuals can be obtained: \n",
    "$$\n",
    "e_i=y_i-\\hat{y_i}\n",
    "$$\n",
    "    \n",
    "at each observed point $x_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include a new predictor variable\n",
    "auto['horsepower2'] = auto.horsepower**2\n",
    "auto.head(3) #show "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "X = auto.horsepower.values.reshape(-1,1)\n",
    "y = auto.mpg\n",
    "\n",
    "# Load the model \n",
    "regr_model = skl_lm.LinearRegression()\n",
    "\n",
    "# Linear fit\n",
    "regr_model.fit(X, y)\n",
    "\n",
    "auto['pred1'] = regr_model.predict(X)\n",
    "auto['resid1'] = auto.mpg - auto.pred1\n",
    "\n",
    "# Quadratic fit\n",
    "X2 = auto[['horsepower', 'horsepower2']].as_matrix()\n",
    "regr_model.fit(X2, y)\n",
    "\n",
    "auto['pred2'] = regr_model.predict(X2)\n",
    "auto['resid2'] = auto.mpg - auto.pred2\n",
    "\n",
    "auto.head(3) #show "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of the residuals\n",
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize=(12,5))\n",
    "\n",
    "# Left plot (Linear regression)\n",
    "\n",
    "# Plot x-axis predicted response and y-axis residual values for each data point\n",
    "\n",
    "# Smooth fitting\n",
    "# sns.regplot with lowess: use statsmodels to estimate a nonparametric lowess model \n",
    "# (locally weighted linear regression)\n",
    "sns.regplot(auto.pred1, auto.resid1, lowess=True, \n",
    "            ax=ax1, line_kws={'color':'r', 'lw':1})\n",
    "ax1.hlines(0,\n",
    "           xmin=ax1.xaxis.get_data_interval()[0],\n",
    "           xmax=ax1.xaxis.get_data_interval()[1], \n",
    "           linestyles='dotted')\n",
    "ax1.set_title('Residual Plot for Linear Fit')\n",
    "\n",
    "# Right plot\n",
    "sns.regplot(auto.pred2, auto.resid2, lowess=True,\n",
    "            line_kws={'color':'r', 'lw':1}, ax=ax2)\n",
    "ax2.hlines(0,\n",
    "           xmin=ax2.xaxis.get_data_interval()[0],\n",
    "           xmax=ax2.xaxis.get_data_interval()[1], \n",
    "           linestyles='dotted')\n",
    "ax2.set_title('Residual Plot for Quadratic Fit')\n",
    "\n",
    "for ax in fig.axes:\n",
    "    ax.set_xlabel('$\\hat{y}_i$')\n",
    "    ax.set_ylabel('$e_i$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The red line is a smooth fit of the residuals, to identify visually the trend. \n",
    "* Left: a linear regression of mpg on horsepower. A strong pattern indicates non-linearity in the data. \n",
    "* Right: a linear regression of mpg on horsepower and horsepower$^2$. There is no clear pattern on the residual. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
