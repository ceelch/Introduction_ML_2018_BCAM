{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression: K Nearest Neighbour\n",
    "\n",
    "Introduction to Machine Learning, BCAM & UPV/EHU course, by Carlos Cernuda, Ekhine Irurozki and Aritz Perez.\n",
    "\n",
    "\n",
    "## References \n",
    "\n",
    "* James, G., Witten, D., Hastie, T., & Tibshirani, R. (2013). \n",
    "An introduction to statistical learning (Vol. 112). New York: springer.\n",
    "* Data sets: http://www-bcf.usc.edu/~gareth/ISL/data.html\n",
    "* SCIKIT-LEARN library example http://scikit-learn.org\n",
    "* References Jupyter notebooks:\n",
    "    - R. Jordan Crouser at Smith College for SDS293: Machine Learning (Spring 2016)\n",
    "    http://www.science.smith.edu/~jcrouser/SDS293/labs/lab10-py.html\n",
    "    - General Assembly's Data Science course in Washington, DC\n",
    "    https://github.com/justmarkham/DAT4\n",
    "    - An Introduction to Statistical Learning (James, Witten, Hastie, Tibshirani, 2013) adapted to Python code\n",
    "    https://github.com/JWarmenhoven/ISLR-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "import numpy as np #scientific computing (n-dim arrays, etc)\n",
    "import pandas as pd #data analysis library\n",
    "##########################################################\n",
    "# Plots:\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns #visualization library based on matplotlib\n",
    "%matplotlib inline\n",
    "plt.style.use(['seaborn-white'])   \n",
    "params = {'legend.fontsize': 'xx-large',\n",
    "              'figure.figsize': (15, 5),\n",
    "              'axes.labelsize': 'xx-large',\n",
    "              'axes.titlesize':'xx-large',\n",
    "              'xtick.labelsize':'xx-large',\n",
    "              'ytick.labelsize':'xx-large'}    \n",
    "pylab.rcParams.update(params)  #fix the parameters for the plots\n",
    "\n",
    "pd.set_option('display.notebook_repr_html', False)\n",
    "##########################################################\n",
    "# SKLEARN: scikit-learn machine learning tools\n",
    "from sklearn import neighbors \n",
    "#provides functionality for unsupervised and supervised neighbors-based learning methods\n",
    "##########################################################\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data non linear \n",
    "X = np.sort(5 * np.random.rand(40, 1), axis=0)\n",
    "y = np.sin(X).ravel() #Return a contiguous flattened array.\n",
    "# Add noise to targets\n",
    "y[::5] += 1 * (0.5 - np.random.rand(8))\n",
    "\n",
    "# Fit regression model\n",
    "# select parameter K\n",
    "n_neighbors = 5\n",
    "\n",
    "# New samples to predict\n",
    "test = np.linspace(0, 5, 500)[:, np.newaxis]\n",
    "\n",
    "# Model\n",
    "knn_model = neighbors.KNeighborsRegressor(n_neighbors, weights='uniform')\n",
    "test_knn_uniform = knn_model.fit(X, y).predict(test)\n",
    "\n",
    "# Plots\n",
    "plt.figure(figsize=(8,8))\n",
    "#\n",
    "plt.scatter(X, y, c='k', label='data')\n",
    "#\n",
    "plt.scatter(test, test_knn_uniform, c='g', label='KNN uniform')\n",
    "#plt.plot(T, y_knn_uniform, c='g', linewidth=1)\n",
    "#\n",
    "plt.axis('tight')\n",
    "plt.legend()\n",
    "plt.title(\"KNN (k = \" +str(n_neighbors)+ \", weights = uniform)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN distance weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data non linear \n",
    "X = np.sort(5 * np.random.rand(40, 1), axis=0)\n",
    "y = np.sin(X).ravel()\n",
    "# Add noise to targets\n",
    "y[::5] += 1 * (0.5 - np.random.rand(8))\n",
    "\n",
    "# Fit regression model\n",
    "# select parameter K\n",
    "n_neighbors = 5\n",
    "\n",
    "# New samples to predict\n",
    "test = np.linspace(0, 5, 100)[:, np.newaxis]\n",
    "\n",
    "# Model\n",
    "knn_model_d = neighbors.KNeighborsRegressor(n_neighbors, weights='distance')\n",
    "test_knn_distance = knn_model_d.fit(X, y).predict(test)\n",
    "\n",
    "# Plots\n",
    "plt.figure(figsize=(8,8))\n",
    "#\n",
    "plt.scatter(X, y, c='k', label='data')\n",
    "#\n",
    "plt.scatter(test, test_knn_distance, c='r', label='KNN distance')\n",
    "#plt.plot(T, y_knn_distance, c='r')\n",
    "#\n",
    "plt.axis('tight')\n",
    "plt.legend()\n",
    "plt.title(\"KNN (k = \" +str(n_neighbors)+ \", weights = distance)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression and KNN \n",
    "\n",
    "In what setting will a parametric approach, such as Linear Regression, outperform a non-parametric approach such as KNN? \n",
    "\n",
    "The parametric approach will outperform  if the parametric form selected is close to the true form of the model $f$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sinusoidal shape\n",
    "\n",
    "# Generate sample data non linear \n",
    "X = np.sort(5 * np.random.rand(40, 1), axis=0)\n",
    "y = np.sin(X).ravel()\n",
    "# Add noise to targets\n",
    "y[::5] += 1 * (0.5 - np.random.rand(8))\n",
    "\n",
    "# New samples to predict\n",
    "test = np.linspace(0, 5, 100)[:, np.newaxis]\n",
    "# KNN\n",
    "knn_model = neighbors.KNeighborsRegressor(n_neighbors, weights='uniform')\n",
    "test_knn_uniform = knn_model.fit(X, y).predict(test)\n",
    "# KNN distance\n",
    "knn_model_d = neighbors.KNeighborsRegressor(n_neighbors, weights='distance')\n",
    "test_knn_distance = knn_model_d.fit(X, y).predict(test)\n",
    "\n",
    "# Plots\n",
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize=(12,5))\n",
    "\n",
    "# Left plot (KNN uniform)\n",
    "#\n",
    "ax1.scatter(X, y, c='k', label='data')\n",
    "#\n",
    "ax1.scatter(test, test_knn_uniform, c='g', label='KNN uniform')\n",
    "ax1.plot(test, test_knn_uniform, c='g')\n",
    "#\n",
    "sns.regplot(X, y, order=1, ci=None, scatter=False, label='Linear', ax=ax1, color='b')\n",
    "ax1.legend()\n",
    "# Right plot (KNN distance)\n",
    "#\n",
    "ax2.scatter(X, y, c='k', label='data')\n",
    "ax2.scatter(test, test_knn_distance, c='r', label='KNN distance')\n",
    "ax2.plot(test, test_knn_distance, c='r')\n",
    "#\n",
    "sns.regplot(X, y, order=1, ci=None, scatter=False, label='Linear', ax=ax2, color='b')\n",
    "ax2.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear shape\n",
    "# Generate sample data linear \n",
    "X = np.sort(5 * np.random.rand(40, 1), axis=0)\n",
    "# Add noise to targets\n",
    "y = X + np.random.rand(40,1)\n",
    "\n",
    "# Fit regression model\n",
    "n_neighbors = 5\n",
    "\n",
    "# To predict\n",
    "test = np.linspace(0, 5, 500)[:, np.newaxis]\n",
    "\n",
    "# Model\n",
    "knn_model_uniform = neighbors.KNeighborsRegressor(n_neighbors, weights='uniform')\n",
    "knn_model_distance = neighbors.KNeighborsRegressor(n_neighbors, weights='distance')\n",
    "test_knn_model_uniform = knn_model_uniform.fit(X, y).predict(test)\n",
    "test_knn_model_distance = knn_model_distance.fit(X, y).predict(test)\n",
    "\n",
    "# Plots\n",
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize=(12,5))\n",
    "\n",
    "# Left plot (KNN uniform)\n",
    "#\n",
    "ax1.scatter(X, y, c='k', label='data')\n",
    "#\n",
    "ax1.scatter(test, test_knn_model_uniform, c='g', label='KNN uniform')\n",
    "ax1.plot(test, test_knn_model_uniform, c='g')\n",
    "#\n",
    "sns.regplot(X, y, order=1, ci=None, scatter=False, label='Linear', ax=ax1, color='b')\n",
    "ax1.legend()\n",
    "# Right plot (KNN distance)\n",
    "#\n",
    "ax2.scatter(X, y, c='k', label='data')\n",
    "ax2.scatter(test, test_knn_model_distance, c='r', label='KNN distance')\n",
    "ax2.plot(test, test_knn_model_distance, c='r')\n",
    "#\n",
    "sns.regplot(X, y, order=1, ci=None, scatter=False, label='Linear', ax=ax2, color='b')\n",
    "ax2.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Danger! Overfitting risk!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
